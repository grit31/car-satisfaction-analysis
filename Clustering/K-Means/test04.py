import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import (
    silhouette_score, adjusted_rand_score,
    normalized_mutual_info_score, homogeneity_score,
    completeness_score, v_measure_score
)
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import itertools
# æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
# ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['axes.unicode_minus'] = False
# 1. åŠ è½½æ•°æ®
file_path = "..\\..\\car+evaluation\\car.data"  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„
column_names = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "car_acceptability"]
df = pd.read_csv(file_path, names=column_names)

# 2. è‡ªå®šä¹‰æ˜ å°„ï¼ˆä»1å¼€å§‹çš„è¯­ä¹‰ç¼–ç ï¼‰
map_buying = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_maint = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_doors = {'2': 1, '3': 2, '4': 3, '5more': 4}
map_persons = {'2': 1, '4': 2, 'more': 3}
map_lug_boot = {'small': 1, 'med': 2, 'big': 3}
map_safety = {'low': 1, 'med': 2, 'high': 3}
map_acceptability = {'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}

# åº”ç”¨ç¼–ç 
X = df.drop(columns=["car_acceptability"]).copy()
X["buying"] = X["buying"].map(map_buying)
X["maint"] = X["maint"].map(map_maint)
X["doors"] = X["doors"].map(map_doors)
X["persons"] = X["persons"].map(map_persons)
X["lug_boot"] = X["lug_boot"].map(map_lug_boot)
X["safety"] = X["safety"].map(map_safety)

# æ ‡ç­¾ï¼ˆç”¨äºè¯„ä¼°ï¼‰
y_true = df["car_acceptability"].map(map_acceptability)

# 3. ç½‘æ ¼æœç´¢æœ€ä½³å‚æ•°ç»„åˆ
param_grid = {
    "n_clusters": range(2, 11),
    "init": ['k-means++', 'random'],
    "n_init": [5, 10, 20],
    "max_iter": [100, 300]
}

best_score = -1
best_params = None

for params in itertools.product(*param_grid.values()):
    param_dict = dict(zip(param_grid.keys(), params))
    kmeans_model = KMeans(random_state=42, **param_dict)
    labels = kmeans_model.fit_predict(X)
    score = silhouette_score(X, labels)
    if score > best_score:
        best_score = score
        best_params = param_dict

print("âœ… æœ€ä½³å‚æ•°ç»„åˆ:", best_params)
print("âœ… æœ€ä½³Silhouetteå¾—åˆ†:", best_score)

# 4. æ„å»º k=4 æ¨¡å‹
kmeans_4 = KMeans(n_clusters=4, random_state=42, n_init=10)
y_pred_4 = kmeans_4.fit_predict(X)

# 5. ä½¿ç”¨æœ€ä¼˜å‚æ•°æ„å»ºæœ€ä½³æ¨¡å‹
kmeans_best = KMeans(random_state=42, **best_params)
y_pred_best = kmeans_best.fit_predict(X)
best_k = best_params['n_clusters']

# 6. PCA é™ç»´
X_pca = PCA(n_components=2).fit_transform(X)

# 7. å¯è§†åŒ–å¯¹æ¯”
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='tab10', s=10)
axs[0].set_title('True Labels (PCA Projection)')
axs[0].set_xlabel('PC1')
axs[0].set_ylabel('PC2')
axs[0].grid(True)

axs[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_4, cmap='tab10', s=10)
axs[1].set_title('K-Means Clusters (k=4)')
axs[1].set_xlabel('PC1')
axs[1].set_ylabel('PC2')
axs[1].grid(True)

axs[2].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_best, cmap='tab10', s=10)
axs[2].set_title(f'K-Means Clusters (Best k={best_k})')
axs[2].set_xlabel('PC1')
axs[2].set_ylabel('PC2')
axs[2].grid(True)

plt.tight_layout()
plt.savefig("kmeans_cluster_comparison.png", dpi=300)
plt.show()

# 8. èšç±»è¯„ä»·å‡½æ•°
def evaluate_clustering(y_true, y_pred):
    return {
        "Silhouette": silhouette_score(X, y_pred),
        "ARI": adjusted_rand_score(y_true, y_pred),
        "NMI": normalized_mutual_info_score(y_true, y_pred),
        "Homogeneity": homogeneity_score(y_true, y_pred),
        "Completeness": completeness_score(y_true, y_pred),
        "V-Measure": v_measure_score(y_true, y_pred)
    }

# 9. æ„å»ºè¯„ä»·ç»“æœ
results_4 = evaluate_clustering(y_true, y_pred_4)
results_best = evaluate_clustering(y_true, y_pred_best)

comparison_df = pd.DataFrame({
    "Kå€¼": [4, best_k],
    "Silhouette": [results_4["Silhouette"], results_best["Silhouette"]],
    "ARI": [results_4["ARI"], results_best["ARI"]],
    "NMI": [results_4["NMI"], results_best["NMI"]],
    "Homogeneity": [results_4["Homogeneity"], results_best["Homogeneity"]],
    "Completeness": [results_4["Completeness"], results_best["Completeness"]],
    "V-Measure": [results_4["V-Measure"], results_best["V-Measure"]]
})

# 10. ä¿å­˜ä¸º CSV
comparison_df.to_csv("kmeans_comparison_results.csv", index=False)
print("âœ… å·²ä¿å­˜èšç±»æ•ˆæœå¯¹æ¯”è¡¨ä¸º 'kmeans_comparison_results.csv'")
print(comparison_df.to_string(index=False))

# 11. æ‰“å°èšç±»ä¸­å¿ƒï¼ˆæœªè§£ç ï¼‰
print("\nğŸ“Œ K=4 çš„èšç±»ä¸­å¿ƒï¼ˆç¼–ç æ•°å€¼ï¼‰:")
print(pd.DataFrame(kmeans_4.cluster_centers_, columns=X.columns).round(2).to_string(index=False))

print(f"\nğŸ“Œ æœ€ä½³K={best_k} çš„èšç±»ä¸­å¿ƒï¼ˆç¼–ç æ•°å€¼ï¼‰:")
print(pd.DataFrame(kmeans_best.cluster_centers_, columns=X.columns).round(2).to_string(index=False))

# 12. æ‰“å°èšç±»ä¸­å¿ƒï¼ˆè§£ç åï¼‰
def decode_centroids(centroids):
    decoded = []
    reverse_maps = {
        'buying': {v: k for k, v in map_buying.items()},
        'maint': {v: k for k, v in map_maint.items()},
        'doors': {v: k for k, v in map_doors.items()},
        'persons': {v: k for k, v in map_persons.items()},
        'lug_boot': {v: k for k, v in map_lug_boot.items()},
        'safety': {v: k for k, v in map_safety.items()}
    }
    for row in centroids:
        decoded_row = []
        for idx, col in enumerate(X.columns):
            val = int(round(row[idx]))
            decoded_val = reverse_maps[col].get(val, f"(?)")
            decoded_row.append(decoded_val)
        decoded.append(decoded_row)
    return pd.DataFrame(decoded, columns=X.columns)

centroids_k4_decoded = decode_centroids(kmeans_4.cluster_centers_)
centroids_best_decoded = decode_centroids(kmeans_best.cluster_centers_)

print("\nğŸ“Œ K=4 çš„èšç±»ä¸­å¿ƒï¼ˆè§£ç åï¼‰:")
print(centroids_k4_decoded.to_string(index=False))

print(f"\nğŸ“Œ æœ€ä½³K={best_k} çš„èšç±»ä¸­å¿ƒï¼ˆè§£ç åï¼‰:")
print(centroids_best_decoded.to_string(index=False))

# åˆå¹¶æ˜¾ç¤º
print("\nğŸ“Š èšç±»ä¸­å¿ƒå¯¹æ¯”åˆ†æï¼ˆè§£ç ååˆå¹¶æ˜¾ç¤ºï¼‰:")
centroids_k4_decoded["èšç±»æ¨¡å‹"] = "K=4"
centroids_best_decoded["èšç±»æ¨¡å‹"] = f"K={best_k}"
combined_centroids = pd.concat([centroids_k4_decoded, centroids_best_decoded], ignore_index=True)
print(combined_centroids.to_string(index=False))

# 13. ä¿å­˜èšç±»ä¸­å¿ƒä¸º CSV
combined_centroids.to_csv("centroids_comparison.csv", index=False, encoding='utf-8-sig')
print("âœ… å·²ä¿å­˜èšç±»ä¸­å¿ƒå¯¹æ¯”è¡¨ä¸º 'centroids_comparison.csv'")

# 14. æ‰“å°æ¯ç±»æ ·æœ¬æ•°é‡ç»Ÿè®¡
print("\nğŸ“¦ K=4 èšç±»æ¨¡å‹çš„æ¯ç±»æ ·æœ¬æ•°é‡ï¼š")
cluster_counts_k4 = pd.Series(y_pred_4).value_counts().sort_index()
for i, count in cluster_counts_k4.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

print(f"\nğŸ“¦ æœ€ä½³K={best_k} èšç±»æ¨¡å‹çš„æ¯ç±»æ ·æœ¬æ•°é‡ï¼š")
cluster_counts_best = pd.Series(y_pred_best).value_counts().sort_index()
for i, count in cluster_counts_best.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

# 15. å¯è§†åŒ–èšç±»æ ·æœ¬æ•°é‡åˆ†å¸ƒ
fig, axs = plt.subplots(1, 2, figsize=(14, 5))

# å·¦å›¾ - K=4
axs[0].bar(cluster_counts_k4.index, cluster_counts_k4.values, color='skyblue')
axs[0].set_title("K=4 èšç±»æ ·æœ¬åˆ†å¸ƒ")
axs[0].set_xlabel("ç°‡ç¼–å·")
axs[0].set_ylabel("æ ·æœ¬æ•°é‡")
axs[0].set_xticks(cluster_counts_k4.index)
for i, v in enumerate(cluster_counts_k4.values):
    axs[0].text(i, v + 5, str(v), ha='center')

# å³å›¾ - Best K
axs[1].bar(cluster_counts_best.index, cluster_counts_best.values, color='salmon')
axs[1].set_title(f"K={best_k} èšç±»æ ·æœ¬åˆ†å¸ƒ")
axs[1].set_xlabel("ç°‡ç¼–å·")
axs[1].set_ylabel("æ ·æœ¬æ•°é‡")
axs[1].set_xticks(cluster_counts_best.index)
for i, v in enumerate(cluster_counts_best.values):
    axs[1].text(i, v + 5, str(v), ha='center')

plt.tight_layout()
plt.savefig("kmeans_cluster_sample_distribution.png", dpi=300)
plt.show()

print("âœ… å·²ä¿å­˜èšç±»æ ·æœ¬åˆ†å¸ƒæŸ±çŠ¶å›¾ä¸º 'cluster_sample_distribution.png'")
