import pandas as pd
import numpy as np
from sklearn.cluster import MeanShift, estimate_bandwidth
from sklearn.metrics import (
    silhouette_score, adjusted_rand_score,
    normalized_mutual_info_score, homogeneity_score,
    completeness_score, v_measure_score
)
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import itertools
# æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
# ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['axes.unicode_minus'] = False
# 1. åŠ è½½æ•°æ®
file_path = "..\\..\\car+evaluation\\car.data"
column_names = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "car_acceptability"]
df = pd.read_csv(file_path, names=column_names)

# 2. è‡ªå®šä¹‰ä»1å¼€å§‹çš„è¯­ä¹‰ç¼–ç 
map_buying = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_maint = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_doors = {'2': 1, '3': 2, '4': 3, '5more': 4}
map_persons = {'2': 1, '4': 2, 'more': 3}
map_lug_boot = {'small': 1, 'med': 2, 'big': 3}
map_safety = {'low': 1, 'med': 2, 'high': 3}
map_acceptability = {'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}

X = df.drop(columns=["car_acceptability"]).copy()
X["buying"] = X["buying"].map(map_buying)
X["maint"] = X["maint"].map(map_maint)
X["doors"] = X["doors"].map(map_doors)
X["persons"] = X["persons"].map(map_persons)
X["lug_boot"] = X["lug_boot"].map(map_lug_boot)
X["safety"] = X["safety"].map(map_safety)
y_true = df["car_acceptability"].map(map_acceptability)

# 3. ç½‘æ ¼æœç´¢
param_grid = {
    "bandwidth": [0.5, 1.0, 1.5, 2.0],
    "bin_seeding": [True, False],
    "cluster_all": [True, False]
}
best_score = -1
best_params = None

for params in itertools.product(*param_grid.values()):
    param_dict = dict(zip(param_grid.keys(), params))
    try:
        model = MeanShift(**param_dict)
        labels = model.fit_predict(X)
        if len(set(labels)) < 2:
            continue
        score = silhouette_score(X, labels)
        if score > best_score:
            best_score = score
            best_params = param_dict
    except Exception:
        continue

print("âœ… æœ€ä½³å‚æ•°ç»„åˆ:", best_params)
print("âœ… æœ€ä½³Silhouetteå¾—åˆ†:", best_score)

# 4. æ„å»ºæ¨¡å‹
default_bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)
meanshift_4 = MeanShift(bandwidth=default_bandwidth, bin_seeding=True)
y_pred_4 = meanshift_4.fit_predict(X)

meanshift_best = MeanShift(**best_params)
y_pred_best = meanshift_best.fit_predict(X)
best_k = len(np.unique(y_pred_best))

# 5. å¯è§†åŒ–
X_pca = PCA(n_components=2).fit_transform(X)
fig, axs = plt.subplots(1, 3, figsize=(18, 6))
axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='tab10', s=10)
axs[0].set_title("True Labels (PCA Projection)")
axs[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_4, cmap='tab10', s=10)
axs[1].set_title("MeanShift Default")
axs[2].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_best, cmap='tab10', s=10)
axs[2].set_title(f"MeanShift Best (k={best_k})")

for ax in axs:
    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.grid(True)

plt.tight_layout()
plt.savefig("meanshift_cluster_comparison.png", dpi=300)
plt.show()

# 6. èšç±»è¯„ä»·
def evaluate_clustering(y_true, y_pred):
    return {
        "Silhouette": silhouette_score(X, y_pred) if len(set(y_pred)) > 1 else None,
        "ARI": adjusted_rand_score(y_true, y_pred),
        "NMI": normalized_mutual_info_score(y_true, y_pred),
        "Homogeneity": homogeneity_score(y_true, y_pred),
        "Completeness": completeness_score(y_true, y_pred),
        "V-Measure": v_measure_score(y_true, y_pred)
    }

results_4 = evaluate_clustering(y_true, y_pred_4)
results_best = evaluate_clustering(y_true, y_pred_best)

comparison_df = pd.DataFrame({
    "Kå€¼": [len(np.unique(y_pred_4)), best_k],
    "Silhouette": [results_4["Silhouette"], results_best["Silhouette"]],
    "ARI": [results_4["ARI"], results_best["ARI"]],
    "NMI": [results_4["NMI"], results_best["NMI"]],
    "Homogeneity": [results_4["Homogeneity"], results_best["Homogeneity"]],
    "Completeness": [results_4["Completeness"], results_best["Completeness"]],
    "V-Measure": [results_4["V-Measure"], results_best["V-Measure"]]
})
comparison_df.to_csv("meanshift_comparison_results.csv", index=False)
print("âœ… å·²ä¿å­˜èšç±»æ•ˆæœå¯¹æ¯”è¡¨ä¸º 'meanshift_comparison_results.csv'")
print(comparison_df.to_string(index=False))

# 7. è§£ç èšç±»ä¸­å¿ƒ
reverse_maps = {
    'buying': {v: k for k, v in map_buying.items()},
    'maint': {v: k for k, v in map_maint.items()},
    'doors': {v: k for k, v in map_doors.items()},
    'persons': {v: k for k, v in map_persons.items()},
    'lug_boot': {v: k for k, v in map_lug_boot.items()},
    'safety': {v: k for k, v in map_safety.items()}
}
def decode_centroids(centroids_df):
    decoded = []
    for _, row in centroids_df.iterrows():
        decoded_row = []
        for col in X.columns:
            val = int(round(row[col]))
            decoded_val = reverse_maps[col].get(val, "(?)")
            decoded_row.append(decoded_val)
        decoded.append(decoded_row)
    return pd.DataFrame(decoded, columns=X.columns)

centroids_k4 = pd.DataFrame(meanshift_4.cluster_centers_, columns=X.columns).round(2)
centroids_best = pd.DataFrame(meanshift_best.cluster_centers_, columns=X.columns).round(2)
centroids_k4_decoded = decode_centroids(centroids_k4)
centroids_best_decoded = decode_centroids(centroids_best)

# âœ… å¯¹é½æ ¼å¼è¾“å‡º
print("\nğŸ“Œ K=4 çš„èšç±»ä¸­å¿ƒï¼ˆè§£ç åï¼‰:")
print(centroids_k4_decoded.to_string(index=False))

print(f"\nğŸ“Œ æœ€ä½³K={best_k} çš„èšç±»ä¸­å¿ƒï¼ˆè§£ç åï¼‰:")
print(centroids_best_decoded.to_string(index=False))

print("\nğŸ“Š èšç±»ä¸­å¿ƒå¯¹æ¯”åˆ†æï¼ˆè§£ç ååˆå¹¶æ˜¾ç¤ºï¼‰:")
centroids_k4_decoded["èšç±»æ¨¡å‹"] = "K=4"
centroids_best_decoded["èšç±»æ¨¡å‹"] = f"K={best_k}"
combined_centroids = pd.concat([centroids_k4_decoded, centroids_best_decoded], ignore_index=True)
print(combined_centroids.to_string(index=False))

# 13. ä¿å­˜èšç±»ä¸­å¿ƒä¸º CSV
combined_centroids.to_csv("centroids_comparison.csv", index=False, encoding='utf-8-sig')
print("âœ… å·²ä¿å­˜èšç±»ä¸­å¿ƒå¯¹æ¯”è¡¨ä¸º 'centroids_comparison.csv'")

# 14. æ ·æœ¬æ•°é‡ç»Ÿè®¡
print("\nğŸ“¦ K=4 èšç±»æ¨¡å‹çš„æ¯ç±»æ ·æœ¬æ•°é‡ï¼š")
cluster_counts_k4 = pd.Series(y_pred_4).value_counts().sort_index()
for i, count in cluster_counts_k4.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

print(f"\nğŸ“¦ æœ€ä½³K={best_k} èšç±»æ¨¡å‹çš„æ¯ç±»æ ·æœ¬æ•°é‡ï¼š")
cluster_counts_best = pd.Series(y_pred_best).value_counts().sort_index()
for i, count in cluster_counts_best.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

# 15. æŸ±çŠ¶å›¾å¯è§†åŒ–
fig, axs = plt.subplots(1, 2, figsize=(14, 5))

axs[0].bar(cluster_counts_k4.index, cluster_counts_k4.values, color='skyblue')
axs[0].set_title("K=4 èšç±»æ ·æœ¬åˆ†å¸ƒ")
axs[0].set_xlabel("ç°‡ç¼–å·")
axs[0].set_ylabel("æ ·æœ¬æ•°é‡")
axs[0].set_xticks(cluster_counts_k4.index)
for i, v in enumerate(cluster_counts_k4.values):
    axs[0].text(i, v + 5, str(v), ha='center')

axs[1].bar(cluster_counts_best.index, cluster_counts_best.values, color='salmon')
axs[1].set_title(f"K={best_k} èšç±»æ ·æœ¬åˆ†å¸ƒ")
axs[1].set_xlabel("ç°‡ç¼–å·")
axs[1].set_ylabel("æ ·æœ¬æ•°é‡")
axs[1].set_xticks(cluster_counts_best.index)
for i, v in enumerate(cluster_counts_best.values):
    axs[1].text(i, v + 5, str(v), ha='center')

plt.tight_layout()
plt.savefig("meanshift_cluster_sample_distribution_meanshift.png", dpi=300)
plt.show()
print("âœ… å·²ä¿å­˜èšç±»æ ·æœ¬åˆ†å¸ƒæŸ±çŠ¶å›¾ä¸º 'cluster_sample_distribution_meanshift.png'")
