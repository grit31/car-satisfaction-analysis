
import pandas as pd
import numpy as np
from sklearn.cluster import MeanShift, estimate_bandwidth
from sklearn.metrics import (
    silhouette_score, adjusted_rand_score,
    normalized_mutual_info_score, homogeneity_score,
    completeness_score, v_measure_score
)
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import itertools

# 1. åŠ è½½æ•°æ®
file_path = "car.julei"  # æœ¬åœ°è·¯å¾„
column_names = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "car_acceptability"]
df = pd.read_csv(file_path, names=column_names)

# 2. è‡ªå®šä¹‰æ˜ å°„ï¼ˆä»1å¼€å§‹çš„è¯­ä¹‰ç¼–ç ï¼‰
map_buying = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_maint = {'low': 1, 'med': 2, 'high': 3, 'vhigh': 4}
map_doors = {'2': 1, '3': 2, '4': 3, '5more': 4}
map_persons = {'2': 1, '4': 2, 'more': 3}
map_lug_boot = {'small': 1, 'med': 2, 'big': 3}
map_safety = {'low': 1, 'med': 2, 'high': 3}
map_acceptability = {'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}

X = df.drop(columns=["car_acceptability"]).copy()
X["buying"] = X["buying"].map(map_buying)
X["maint"] = X["maint"].map(map_maint)
X["doors"] = X["doors"].map(map_doors)
X["persons"] = X["persons"].map(map_persons)
X["lug_boot"] = X["lug_boot"].map(map_lug_boot)
X["safety"] = X["safety"].map(map_safety)
y_true = df["car_acceptability"].map(map_acceptability)

# 3. ç½‘æ ¼æœç´¢æœ€ä½³å‚æ•°ç»„åˆï¼ˆSilhouetteå¾—åˆ†ï¼‰
bandwidths = [0.5, 1.0, 1.5, 2.0]
bin_seedings = [True, False]
cluster_alls = [True, False]
best_score = -1
best_params = None

for params in itertools.product(bandwidths, bin_seedings, cluster_alls):
    param_dict = dict(zip(["bandwidth", "bin_seeding", "cluster_all"], params))
    try:
        model = MeanShift(**param_dict)
        labels = model.fit_predict(X)
        if len(set(labels)) < 2:
            continue
        score = silhouette_score(X, labels)
        if score > best_score:
            best_score = score
            best_params = param_dict
    except Exception:
        continue

print("âœ… æœ€ä½³å‚æ•°ç»„åˆ:", best_params)
print("âœ… æœ€ä½³Silhouetteå¾—åˆ†:", best_score)

# 4. æ„å»ºé»˜è®¤æ¨¡å‹ï¼ˆä¼°ç®—å¸¦å®½ï¼‰
default_bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)
meanshift_4 = MeanShift(bandwidth=default_bandwidth, bin_seeding=True)
y_pred_4 = meanshift_4.fit_predict(X)

# 5. ä½¿ç”¨æœ€ä½³å‚æ•°æ„å»ºæ¨¡å‹
meanshift_best = MeanShift(**best_params)
y_pred_best = meanshift_best.fit_predict(X)
best_k = len(np.unique(y_pred_best))

# 6. PCA ä¸‰å›¾å¯è§†åŒ–
X_pca = PCA(n_components=2).fit_transform(X)
fig, axs = plt.subplots(1, 3, figsize=(18, 6))
axs[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='tab10', s=10)
axs[0].set_title("True Labels (PCA Projection)")
axs[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_4, cmap='tab10', s=10)
axs[1].set_title("MeanShift Default")
axs[2].scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_best, cmap='tab10', s=10)
axs[2].set_title(f"MeanShift Best (k={best_k})")
for ax in axs:
    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.grid(True)
plt.tight_layout()
plt.savefig("meanshift_cluster_comparison.png", dpi=300)
plt.close()

# 7. èšç±»è¯„ä»·å‡½æ•°
def evaluate_clustering(y_true, y_pred):
    return {
        "Silhouette": silhouette_score(X, y_pred) if len(set(y_pred)) > 1 else None,
        "ARI": adjusted_rand_score(y_true, y_pred),
        "NMI": normalized_mutual_info_score(y_true, y_pred),
        "Homogeneity": homogeneity_score(y_true, y_pred),
        "Completeness": completeness_score(y_true, y_pred),
        "V-Measure": v_measure_score(y_true, y_pred)
    }

results_4 = evaluate_clustering(y_true, y_pred_4)
results_best = evaluate_clustering(y_true, y_pred_best)

comparison_df = pd.DataFrame({
    "Kå€¼": [len(np.unique(y_pred_4)), best_k],
    "Silhouette": [results_4["Silhouette"], results_best["Silhouette"]],
    "ARI": [results_4["ARI"], results_best["ARI"]],
    "NMI": [results_4["NMI"], results_best["NMI"]],
    "Homogeneity": [results_4["Homogeneity"], results_best["Homogeneity"]],
    "Completeness": [results_4["Completeness"], results_best["Completeness"]],
    "V-Measure": [results_4["V-Measure"], results_best["V-Measure"]]
})
comparison_df.to_csv("meanshift_comparison_results.csv", index=False)

# 8. æ‰“å°èšç±»ä¸­å¿ƒï¼ˆæœªè§£ç ï¼‰
centers_k4 = pd.DataFrame(meanshift_4.cluster_centers_, columns=X.columns).round(2)
centers_best = pd.DataFrame(meanshift_best.cluster_centers_, columns=X.columns).round(2)
centers_k4["èšç±»æ¨¡å‹"] = "Default"
centers_best["èšç±»æ¨¡å‹"] = f"K={best_k}"
combined_centroids = pd.concat([centers_k4, centers_best], ignore_index=True)
combined_centroids.to_csv("centroids_comparison.csv", index=False, encoding="utf-8-sig")

# 9. æ‰“å°æ ·æœ¬æ•°é‡ç»Ÿè®¡ + å¯è§†åŒ–æŸ±çŠ¶å›¾
print("\nğŸ“¦ MeanShift é»˜è®¤æ¨¡å‹æ¯ç±»æ ·æœ¬æ•°:")
cluster_counts_k4 = pd.Series(y_pred_4).value_counts().sort_index()
for i, count in cluster_counts_k4.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

print(f"\nğŸ“¦ MeanShift æœ€ä½³æ¨¡å‹ (K={best_k}) æ¯ç±»æ ·æœ¬æ•°:")
cluster_counts_best = pd.Series(y_pred_best).value_counts().sort_index()
for i, count in cluster_counts_best.items():
    print(f"Cluster {i}: {count} ä¸ªæ ·æœ¬")

fig, axs = plt.subplots(1, 2, figsize=(14, 5))
axs[0].bar(cluster_counts_k4.index, cluster_counts_k4.values, color='skyblue')
axs[0].set_title("MeanShift Default èšç±»æ ·æœ¬åˆ†å¸ƒ")
axs[0].set_xlabel("ç°‡ç¼–å·")
axs[0].set_ylabel("æ ·æœ¬æ•°é‡")
axs[0].set_xticks(cluster_counts_k4.index)
for i, v in enumerate(cluster_counts_k4.values):
    axs[0].text(i, v + 5, str(v), ha='center')

axs[1].bar(cluster_counts_best.index, cluster_counts_best.values, color='salmon')
axs[1].set_title(f"MeanShift Best èšç±»æ ·æœ¬åˆ†å¸ƒ (k={best_k})")
axs[1].set_xlabel("ç°‡ç¼–å·")
axs[1].set_ylabel("æ ·æœ¬æ•°é‡")
axs[1].set_xticks(cluster_counts_best.index)
for i, v in enumerate(cluster_counts_best.values):
    axs[1].text(i, v + 5, str(v), ha='center')

plt.tight_layout()
plt.savefig("cluster_sample_distribution_meanshift.png", dpi=300)
plt.show()
